{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38577af2-d648-4b03-82b5-f44adadae9b0",
   "metadata": {},
   "source": [
    "#### Hasta este punto tenemos nuestras tablas procesadas (movies, ratings y tags) de forma correcta. El cliente nos ha solicitado apoyar al departamento de Marketing a realizar algunas consultas y a generar una única tabla y realizar algunos ajustes a la tabla final antes de poder almacenarla.\n",
    "\n",
    "##### Nota: Para poder trabajar con este notebook es necesario haber terminado el ejercicio de la sesión 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7aed2b-a75e-4a30-ba90-d6a21f55965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML <style>pre { white-space: pre !important; }</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5e3c8-5689-4c7c-83d3-ec7b70d0e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame, Column, Row}\n",
    "import org.apache.spark.sql.{functions => f}\n",
    "import org.apache.spark.sql.{types => t}\n",
    "\n",
    "def difference(l1: Seq[String], l2: Seq[String]): Seq[Column] =\n",
    "    l1.diff(l2).map(colName => f.col(colName))\n",
    "\n",
    "def readTmpDf(dfSeq: Seq[String]): Map[String, DataFrame] =\n",
    "    dfSeq.map(table_name => (table_name, spark.read.parquet(\"../../resources/data/tmp/parquet/\" + table_name))).toMap\n",
    "\n",
    "def writeTmpDf(dfSeq: Seq[(DataFrame, String)]): Unit = \n",
    "    dfSeq.foreach{case (df: DataFrame, name: String) => df.write.mode(\"overwrite\").parquet(\"../../resources/data/tmp/parquet/\" + name)}\n",
    "\n",
    "def schema_to_ddl(df: DataFrame): String = df.schema.toDDL.replace(\" NOT NULL\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f34787-67c5-4d2b-a592-4f29e250e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "// Creación de sesión de Spark\n",
    "val spark = SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"ejercicio_8\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT-6\")\n",
    "\n",
    "// Carga de tablas requeridas\n",
    "val RootPath = \"../../resources/data/tmp/parquet/\"\n",
    "val namesList = Seq(\"07/movies\", \"07/ratings\", \"07/tags_p2\")\n",
    "val dfMap = readTmpDf(namesList)\n",
    "\n",
    "val moviesDf = dfMap(\"07/movies\")\n",
    "val ratingsDf = dfMap(\"07/ratings\")\n",
    "val tagsDf = dfMap(\"07/tags_p2\")\n",
    "\n",
    "moviesDf.show(1, false)\n",
    "ratingsDf.show(1)\n",
    "tagsDf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71d4d1-826a-4993-bc6e-ee87939e3525",
   "metadata": {},
   "source": [
    "#### En la siguiente imagen se muestra una representación a traves del diagrama de Venn sobre cada tabla (moviesDf, ratingsDf y tagsDf) la cual fue contruida por el departamento de Marketing, el problema es que no saben la cantidad de datos de cada conjunto.\n",
    "##### El cliente nos han solicitado obtener la cantidad de registros de cada conjunto de datos representado por las siguientes letras:\n",
    "- ##### A: Registros de moviesDf que no tiene filas coincidentes con las tablas ratingsDf y tagsDf\n",
    "- ##### B: Registros de ratingsDf que no tiene filas coincidentes con las tablas moviesDf y tagsDf\n",
    "- ##### C: Registros de tagsDf que no tiene filas coincidentes con las tablas moviesDf y ratingsDf\n",
    "- ##### D: Registros de moviesDf y ratingsDf que no tiene filas coincidentes con la tabla tagsDf\n",
    "- ##### E: Registros de moviesDf y tagsDf que no tiene filas coincidentes con la tabla ratingsDf\n",
    "- ##### F: Registros de ratingsDf y tagsDf que no tiene filas coincidentes con la tabla moviesDf\n",
    "- ##### G: Registros que contiene datos coincidentes en las tablas moviesDf, ratingsDf y tagsDf\n",
    "-  Una tabla tiene registros coincidentes con otra cuando comparten el mismo valor en la columna \"movie_id\"\n",
    "\n",
    "![title](../../resources/img/Tablas_conjuntos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07f716-9806-4388-ad1a-b0fa9f4266cf",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO ->    Obtener los conjuntos de datos listados en el diagrama de Venn con operaciones de tipo join, con la finalidad de ahorrar recursos el cliente nos ha solicitado que en la salida de cada transformación el dataframe resultante contenga únicamente la columna \"movie_id\" (basta con utilizar únicante una trasnsformación select al inicio de las operaciones join y utilizar únicamente joins del tipo **left_semi** y **left_anti**).\n",
    "- ##### Los dataframes resultantes se almacenarán en las siguientes variables:\n",
    "    - ##### A_df -> Conjunto A\n",
    "    - ##### B_df -> Conjunto B\n",
    "    - ##### C_df -> Conjunto C\n",
    "    - ##### D_df -> Conjunto D\n",
    "    - ##### E_df -> Conjunto E\n",
    "    - ##### F_df -> Conjunto F\n",
    "    - ##### G_df -> Conjunto G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bb862-0181-4a7e-86bd-1611fe915f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "// Conjunto A:\n",
    "val Adf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto B:\n",
    "val Bdf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto C:\n",
    "val Cdf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto D:\n",
    "val Ddf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto E:\n",
    "val Edf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto F:\n",
    "val Fdf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto G:\n",
    "val Gdf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f75654c-f84e-4c13-83f2-445301d53f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "Bdf.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida de cada dataframe (desde A hasta G):\n",
    "+--------+\n",
    "|movie_id|\n",
    "+--------+\n",
    "|  179995|\n",
    "+--------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec544e2-6d98-427f-a16a-f74588d26ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "assert(Adf.count() == 0)\n",
    "assert(Bdf.count() == 4270)\n",
    "assert(Cdf.count() == 539)\n",
    "assert(Ddf.count() == 28815)\n",
    "assert(Edf.count() == 2759)\n",
    "assert(Fdf.count() == 2251)\n",
    "assert(Gdf.count() == 47903)\n",
    "\n",
    "assert(Adf.columns.size == 1)\n",
    "assert(Bdf.columns.size == 1)\n",
    "assert(Cdf.columns.size == 1)\n",
    "assert(Ddf.columns.size == 1)\n",
    "assert(Edf.columns.size == 1)\n",
    "assert(Fdf.columns.size == 1)\n",
    "assert(Gdf.columns.size == 1)\n",
    "\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63eaf5-b3fe-4166-93c7-7477a3c38748",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO ->    Algunos administradores de base de datos no comprenden el uso de los joins de tipo left_semi y left_anti, por lo tanto el cliente ha solicitado que tambien se realicen las transformaciones con cualquiera de los siguientes tipos de join: **left, right, inner, outer**. Podrías utilizar la transformación filter/where en algunos casos.\n",
    "##### No existe alguna reestricción de qué columnas contiene el dataframe de salida.\n",
    "- ##### Los dataframes resultantes se almacenarán en las siguientes variables:\n",
    "    - ##### A_df -> Conjunto A\n",
    "    - ##### B_df -> Conjunto B\n",
    "    - ##### C_df -> Conjunto C\n",
    "    - ##### D_df -> Conjunto D\n",
    "    - ##### E_df -> Conjunto E\n",
    "    - ##### F_df -> Conjunto F\n",
    "    - ##### G_df -> Conjunto G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35df75-5f96-4721-b9e2-1ae9d42f9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "// Conjunto A:\n",
    "val A_df = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto B:\n",
    "val B_df = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto C:\n",
    "val C_df = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto D:\n",
    "val D_df = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto E:\n",
    "val E_df = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto F:\n",
    "val F_df = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto G:\n",
    "val G_df = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed8ee6-2c1e-435a-bef1-c617303b95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "assert(A_df.count() == 0)\n",
    "assert(B_df.count() == 4270)\n",
    "assert(C_df.count() == 539)\n",
    "assert(D_df.count() == 28815)\n",
    "assert(E_df.count() == 2759)\n",
    "assert(F_df.count() == 2251)\n",
    "assert(G_df.count() == 47903)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2a8be-795b-4217-b5ff-663d8ba63778",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO ->    Con operaciones join genera un dataframe que contenga la union de todos los conjuntos (desde el A hasta el G) sin repetir registros. No utilices las transformaciones de union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc418dd-8cd1-4803-a439-0e7e5cf59437",
   "metadata": {},
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "val universeDf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc3bdb-d072-4a6b-bf85-eef22ce25394",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "universeDf.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida:\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|movie_id|               title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|  100062|My Way (Mai Wei) ...|[Action, Drama, War]|2011|      3.63|         0.83|          64|2014-03-11 21:23:33|[{PRESS-GANGED, 1...|2018-05-26 16:40:54|\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dfa01-26a2-48bc-ac05-aa5d660f3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val data = Seq(Row(\"100062\",\n",
    "                   \"My Way (Mai Wei) (2011)\",\n",
    "                   Seq(\"Action\", \"Drama\", \"War\"),\n",
    "                   2011,\n",
    "                   3.63,\n",
    "                   0.83,\n",
    "                   64L,\n",
    "                   Timestamp.valueOf(\"2014-03-11 21:23:33.0\"),\n",
    "                   Seq(Row(\"FATE\",1L),\n",
    "                       Row(\"PRESS-GANGED\",1L),\n",
    "                       Row(\"WAR\",1L),\n",
    "                       Row(\"WORLD WAR II\",1L)),\n",
    "                   Timestamp.valueOf(\"2018-05-26 16:40:54.0\")))\n",
    "val schema = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"title\", t.StringType),\n",
    "    t.StructField(\"genres\", t.ArrayType(t.StringType)),\n",
    "    t.StructField(\"year\", t.IntegerType),\n",
    "    t.StructField(\"avg_rating\", t.DoubleType),\n",
    "    t.StructField(\"stddev_rating\", t.DoubleType),\n",
    "    t.StructField(\"count_rating\", t.LongType),\n",
    "    t.StructField(\"min_time_rating\", t.TimestampType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType(Seq(\n",
    "        t.StructField(\"tag\", t.StringType),\n",
    "        t.StructField(\"count\", t.LongType)\n",
    "    )))),\n",
    "    t.StructField(\"min_time_tag\", t.TimestampType)\n",
    "    ))\n",
    "val testDf = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)\n",
    "\n",
    "val expectedColumns = Seq(\"movie_id\", \"title\", \"genres\", \"year\",\n",
    "                          \"avg_rating\", \"stddev_rating\", \"count_rating\",\n",
    "                          \"min_time_rating\", \"tag_count\", \"min_time_tag\")\n",
    "\n",
    "assert(universeDf.count() == 86537)\n",
    "assert(universeDf.columns.diff(expectedColumns).size + expectedColumns.diff(universeDf.columns).size == 0)\n",
    "assert(universeDf\n",
    "    .select(expectedColumns.map(f.col):_*)\n",
    "    .filter(f.col(\"movie_id\") === \"100062\")\n",
    "    .except(testDf).count() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc31f99-4163-4721-b33d-b1ecdc8d4b05",
   "metadata": {},
   "source": [
    "#### Actividad 4:\n",
    "##### TO DO ->    La estructura del dataframe final de acuerdo al análisis realizado por marketing es el dado por la union del conjunto de datos: A, D, E y G. Realiza este proceso y almacena el dataframe resultante en la variable \"finalDf\"\n",
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835c048-f0fd-455e-8f2e-725575e9c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "val finalDf = // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cade6f4-ba10-47be-a2e9-f37e0f1ebbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "finalDf.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida:\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|movie_id|           title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|       1|Toy Story (1995)|[Adventure, Anima...|1995|      3.89|         0.93|       76813|1996-01-28 18:00:00|[{TIME TRAVEL, 11...|2006-01-12 19:19:35|\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f51d7-33e5-4e89-9781-6402060cb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val data = Seq(Row(\"100062\",\n",
    "                   \"My Way (Mai Wei) (2011)\",\n",
    "                   Seq(\"Action\", \"Drama\", \"War\"),\n",
    "                   2011,\n",
    "                   3.63,\n",
    "                   0.83,\n",
    "                   64L,\n",
    "                   Timestamp.valueOf(\"2014-03-11 21:23:33.0\"),\n",
    "                   Seq(Row(\"FATE\",1L),\n",
    "                       Row(\"PRESS-GANGED\",1L),\n",
    "                       Row(\"WAR\",1L),\n",
    "                       Row(\"WORLD WAR II\",1L)),\n",
    "                   Timestamp.valueOf(\"2018-05-26 16:40:54.0\")))\n",
    "val schema = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"title\", t.StringType),\n",
    "    t.StructField(\"genres\", t.ArrayType(t.StringType)),\n",
    "    t.StructField(\"year\", t.IntegerType),\n",
    "    t.StructField(\"avg_rating\", t.DoubleType),\n",
    "    t.StructField(\"stddev_rating\", t.DoubleType),\n",
    "    t.StructField(\"count_rating\", t.LongType),\n",
    "    t.StructField(\"min_time_rating\", t.TimestampType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType(Seq(\n",
    "        t.StructField(\"tag\", t.StringType),\n",
    "        t.StructField(\"count\", t.LongType)\n",
    "    )))),\n",
    "    t.StructField(\"min_time_tag\", t.TimestampType)\n",
    "    ))\n",
    "val testDf = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)\n",
    "\n",
    "assert(finalDf.count() == 79477)\n",
    "assert(finalDf.columns.diff(expectedColumns).size + expectedColumns.diff(finalDf.columns).size == 0)\n",
    "assert(finalDf\n",
    "    .select(expectedColumns.map(f.col):_*)\n",
    "    .filter(f.col(\"movie_id\") === \"100062\")\n",
    "    .except(testDf).count() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20399c4b-106f-4696-b246-40f949628469",
   "metadata": {},
   "source": [
    "#### Actividad 5:\n",
    "##### TO DO ->    El cliente nos ha solicitado llenar los valores \"null\" de la columna \"year\", para esto nos ha pedido seguir la siguiente regla:\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_rating\" es null colocar el año de la columna \"min_time_tag\".\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_tag\" es null colocar el año de la columna \"min_time_rating\".\n",
    "- ##### Si la columna \"year\" es null, y las columnas \"min_time_rating\" y \"min_time_tag\" son distintas de null colocar el año menor de las columnas \"min_time_rating\" y \"min_time_tag\", en caso de que el año en ambas columnas sea el mismo colocar dicho año.\n",
    "- ##### En cualquier otro caso mantener el valor entero 1970\n",
    "##### Adicional nos ha solicitado generar una columna llamada \"year_type\" con los siguientes valores:\n",
    "- ##### Si la columna \"year\" venia con un valor distinto a null, asignar el valor \"YO\"\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_rating\" es null colocar \"YT\"\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_tag\" es null colocar \"YR\"\n",
    "- ##### Si la columna \"year\" es null, y las columnas \"min_time_rating\" y \"min_time_tag\" son distintas de null:\n",
    "    - ##### Si \"min_time_rating\" es menor a \"min_time_tag\" colocar \"YR\"\n",
    "    - ##### Si \"min_time_tag\" es menor a \"min_time_rating\" colocar \"YT\"\n",
    "    - ##### Si \"min_time_tag\" es igual a \"min_time_rating\" colocar \"YRT\"\n",
    "- ##### En cualquier otro caso mantener \"YU\"\n",
    "##### Al finalizar este proceso eliminar las columnas \"min_time_rating\" y \"min_time_tag\"\n",
    "- Para resolver estos ejercicios podrías utilizar la función year -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.year.html#pyspark.sql.functions.year\n",
    "##### Este proceso se desarrollará en un método con la firma: def getLastMoviesDf(df: DataFrame): DataFrame\n",
    "##### La estructura del dataframe de salida será:\n",
    "* |-- movie_id: string\n",
    "* |-- title: string\n",
    "* |-- avg_rating: double\n",
    "* |-- count_rating: long\n",
    "* |-- stddev_rating: double\n",
    "* |-- genres: array\n",
    "* |--- |-- element: string\n",
    "* |-- tag_count: array\n",
    "* |--- |-- element: struct\n",
    "* |--- |--- |tag: string\n",
    "* |--- |--- |count: long\n",
    "* |-- year: integer\n",
    "* |-- year_type: string\n",
    "##### NO UTILIZAR withColumn NI withColumnRenamed NI UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae848a85-c931-4c17-bed3-6c1981573395",
   "metadata": {},
   "outputs": [],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def getLastMoviesDf(df: DataFrame): DataFrame =\n",
    "    df // transformaciones a finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68252b23-7945-4b65-9994-20980eb23889",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "val moviesDf = getLastMoviesDf(finalDf)\n",
    "moviesDf.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada (el orden de la columnas podría ser distinto):\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "|movie_id|           title|avg_rating|count_rating|stddev_rating|              genres|           tag_count|year|year_type|\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "|       1|Toy Story (1995)|      3.89|       76813|         0.93|[Adventure, Anima...|[{1990S, 1}, {200...|1995|       YO|\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe845e-3491-4366-8759-49d8eae1b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val expectedRow = Row(\"179479\",\n",
    "                      \"Samadhi Part 1: Maya, the Illusion of the Self\",\n",
    "                      4.19,\n",
    "                      8,\n",
    "                      0.75,\n",
    "                      Seq(\"Documentary\"),\n",
    "                      Seq(Row(\"EASTERN PHILOSOPHY\", 1),\n",
    "                          Row(\"MEDITATION\", 1),\n",
    "                          Row(\"METAPHYSICAL\", 1),\n",
    "                          Row(\"NEW AGE\", 1),\n",
    "                          Row(\"SPIRITUAL\", 1)),\n",
    "                      2017,\n",
    "                      \"YT\")\n",
    "\n",
    "val expectedCountByYearType = Seq(Row(\"YO\", 79235L),\n",
    "                                  Row(\"YR\", 159L),\n",
    "                                  Row(\"YRT\", 55L),\n",
    "                                  Row(\"YT\", 28L))\n",
    "\n",
    "val expectedColumns = Seq(\"movie_id\",\"title\",\"avg_rating\",\"count_rating\",\"stddev_rating\",\"genres\",\"tag_count\",\"year\",\"year_type\")\n",
    "\n",
    "val expectedSchema = \"movie_id STRING,title STRING,avg_rating DOUBLE,count_rating BIGINT,stddev_rating DOUBLE,genres ARRAY<STRING>,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,year INT,year_type STRING\"\n",
    "\n",
    "assert(moviesDf.columns.diff(expectedColumns).size + expectedColumns.diff(moviesDf.columns).size == 0)\n",
    "assert(moviesDf.filter(f.col(\"year\").isNull).count() == 0)\n",
    "assert(moviesDf\n",
    "    .select(expectedColumns.map(f.col):_*)\n",
    "    .filter(f.col(\"movie_id\") === \"179479\")\n",
    "    .collect()(0) == expectedRow)\n",
    "assert(schema_to_ddl(moviesDf.select(expectedColumns.map(f.col):_*)) == expectedSchema)\n",
    "\n",
    "moviesDf.groupBy(f.col(\"year_type\")).count().orderBy(f.col(\"count\").desc).collect()\n",
    "    .zip(expectedCountByYearType)\n",
    "    .foreach(tuple => {\n",
    "        assert(tuple._1.getAs[String](\"year_type\") == tuple._2.getAs[String](0))\n",
    "        assert(tuple._1.getAs[Long](\"count\") == tuple._2.getAs[Long](1))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f87e6-bdcf-4567-a8fe-56d4f1aa36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((moviesDf, \"08/movies\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31a9ac-5552-4e0c-bd94-7f9b92591f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
